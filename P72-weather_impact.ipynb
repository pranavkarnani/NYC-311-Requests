{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels.panel.model import PanelOLS\n",
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('311_borough_weather.csv')\n",
    "df['Y-M-d'] = pd.to_datetime(df['Y-M-d'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function to decompose a series of values into 3 signals - trend, seasonal, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trend_seasonality_error(data, cols): \n",
    "    for col in cols:\n",
    "        res = sm.tsa.seasonal_decompose(data[col], period=12, extrapolate_trend='freq')\n",
    "        data[col+'_trend'] = res.trend\n",
    "        data[col+'_seasonal'] = res.seasonal\n",
    "        data[col+'_error'] = res.resid      \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding the different boroughs with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_mapper = {}\n",
    "\n",
    "for index, value in enumerate(df['Borough'].unique()):\n",
    "    borough_mapper[value] = index\n",
    "\n",
    "df['Borough'] = df['Borough'].map(borough_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y-M-d</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Count</th>\n",
       "      <th>Date</th>\n",
       "      <th>DailyMeanTemp</th>\n",
       "      <th>DailyTempStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.758068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.758068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>558</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.758068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>606</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.758068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>0.758068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1382</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>47.500135</td>\n",
       "      <td>12.899035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>652</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>47.500135</td>\n",
       "      <td>12.899035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>3</td>\n",
       "      <td>939</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>47.500135</td>\n",
       "      <td>12.899035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>47.500135</td>\n",
       "      <td>12.899035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>47.500135</td>\n",
       "      <td>12.899035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6576 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y-M-d  Borough  Count        Date  DailyMeanTemp  DailyTempStd\n",
       "0    2016-01-01        0    689  2016-01-01      41.250000      0.758068\n",
       "1    2016-01-01        1    858  2016-01-01      41.250000      0.758068\n",
       "2    2016-01-01        2    558  2016-01-01      41.250000      0.758068\n",
       "3    2016-01-01        3    606  2016-01-01      41.250000      0.758068\n",
       "4    2016-01-01        4     69  2016-01-01      41.250000      0.758068\n",
       "...         ...      ...    ...         ...            ...           ...\n",
       "6571 2018-12-31        1   1382  2018-12-31      47.500135     12.899035\n",
       "6572 2018-12-31        2    652  2018-12-31      47.500135     12.899035\n",
       "6573 2018-12-31        3    939  2018-12-31      47.500135     12.899035\n",
       "6574 2018-12-31        4    213  2018-12-31      47.500135     12.899035\n",
       "6575 2018-12-31        5     14  2018-12-31      47.500135     12.899035\n",
       "\n",
       "[6576 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating the data on a daily level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_week = df.groupby('Y-M-d').agg({'DailyMeanTemp': 'unique', 'DailyTempStd': 'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_week = df_weather_week.reset_index()\n",
    "df_weather_week['DailyMeanTemp'] = df_weather_week['DailyMeanTemp'].apply(lambda x: x[0])\n",
    "df_weather_week['DailyTempStd'] = df_weather_week['DailyTempStd'].apply(lambda x: x[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the lagged features from AR term - 7 and MA featurs - 2, for each borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_train_data_master = pd.DataFrame()\n",
    "for i in df['Borough'].unique():\n",
    "    df_boro = df[df['Borough'] == i]\n",
    "    df_boro = df_boro.reset_index(drop = True)\n",
    "    df_boro.sort_values(by = 'Y-M-d', inplace = True)\n",
    "\n",
    "    lagged_train_data = df_boro.copy()\n",
    "    trailing_window_size = 7\n",
    "    df_boro_lags = pd.DataFrame()\n",
    "\n",
    "    for window in range(1, trailing_window_size + 1):\n",
    "        shifted = df.loc[:, 'Count'].shift(window)\n",
    "        df_boro_lags[f'lag_{window}'] = shifted\n",
    "        \n",
    "    df_boro_lags['Y-M-d'] = df_boro['Y-M-d']\n",
    "\n",
    "    df_boro_lags = pd.merge(df_boro, df_boro_lags, how = 'inner', on = 'Y-M-d')\n",
    "\n",
    "    ets_train_data = create_trend_seasonality_error(df_boro_lags.copy(), ['Count'])\n",
    "    \n",
    "    ets_train_data['MA_1'] = ets_train_data['Count'].rolling(1).mean().shift(1)\n",
    "    ets_train_data['MA_2'] = ets_train_data['Count'].rolling(2).mean().shift(2)\n",
    "    \n",
    "    ets_train_data = ets_train_data.dropna()\n",
    "    ets_train_data_master = pd.concat([ets_train_data_master, ets_train_data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data being in a panel format, we perform a Panel OLS to account for time dummies and fixed effects. <br>\n",
    "After having accounted for both, we get a p-value for DailyMeanTemp < 0.05 <br>\n",
    "This implies that temperature does play a role in predicting the number of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_train_data_master['Date'] = pd.to_datetime(ets_train_data_master['Date'])\n",
    "ets_train_data_master['Year'] = ets_train_data_master['Date'].apply(lambda x: x.year)\n",
    "ets_train_data_master['Month'] = ets_train_data_master['Date'].apply(lambda x: x.month)\n",
    "ets_train_data_master['Day'] = ets_train_data_master['Date'].apply(lambda x: x.day)\n",
    "\n",
    "del ets_train_data_master['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_train_data_master = pd.get_dummies(ets_train_data_master, columns=['Year', 'Month', 'Day'], drop_first=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of temperature can hence be said is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                  Count   R-squared:                        0.3959\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.6986\n",
      "No. Observations:                6534   R-squared (Within):               0.3959\n",
      "Date:                Sun, Dec 25 2022   R-squared (Overall):              0.6856\n",
      "Time:                        07:03:48   Log-likelihood                -4.173e+04\n",
      "Cov. Estimator:             Clustered                                           \n",
      "                                        F-statistic:                      78.575\n",
      "Entities:                           6   P-value                           0.0000\n",
      "Avg Obs:                       1089.0   Distribution:                 F(54,6474)\n",
      "Min Obs:                       1089.0                                           \n",
      "Max Obs:                       1089.0   F-statistic (robust):         -1.638e+17\n",
      "                                        P-value                           1.0000\n",
      "Time periods:                    1089   Distribution:                 F(54,6474)\n",
      "Avg Obs:                       6.0000                                           \n",
      "Min Obs:                       6.0000                                           \n",
      "Max Obs:                       6.0000                                           \n",
      "                                                                                \n",
      "                               Parameter Estimates                               \n",
      "=================================================================================\n",
      "               Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------\n",
      "DailyMeanTemp    -1.6306     0.8186    -1.9919     0.0464     -3.2353     -0.0258\n",
      "DailyTempStd      0.9573     0.8654     1.1062     0.2687     -0.7392      2.6539\n",
      "lag_1             0.0087     0.0059     1.4591     0.1446     -0.0030      0.0203\n",
      "lag_2            -0.0173     0.0055    -3.1557     0.0016     -0.0281     -0.0066\n",
      "lag_3            -0.0125     0.0057    -2.1980     0.0280     -0.0237     -0.0014\n",
      "lag_4            -0.0120     0.0042    -2.8261     0.0047     -0.0203     -0.0037\n",
      "lag_5            -0.0157     0.0064    -2.4607     0.0139     -0.0281     -0.0032\n",
      "lag_6            -0.0082     0.0033    -2.4598     0.0139     -0.0147     -0.0017\n",
      "lag_7            -0.0231     0.0094    -2.4505     0.0143     -0.0416     -0.0046\n",
      "MA_1              0.5290     0.0209     25.286     0.0000      0.4880      0.5700\n",
      "MA_2              0.0143     0.0500     0.2857     0.7751     -0.0838      0.1124\n",
      "Year_2017         9.4184     12.788     0.7365     0.4614     -15.650      34.487\n",
      "Year_2018         53.608     29.850     1.7959     0.0726     -4.9075      112.12\n",
      "Month_2          -18.215     7.5298    -2.4190     0.0156     -32.975     -3.4536\n",
      "Month_3          -20.119     10.141    -1.9840     0.0473     -39.999     -0.2400\n",
      "Month_4          -18.351     12.000    -1.5292     0.1263     -41.875      5.1735\n",
      "Month_5           24.474     8.6664     2.8240     0.0048      7.4852      41.463\n",
      "Month_6           63.937     22.055     2.8990     0.0038      20.702      107.17\n",
      "Month_7           65.649     23.058     2.8471     0.0044      20.447      110.85\n",
      "Month_8           57.291     21.057     2.7207     0.0065      16.012      98.569\n",
      "Month_9           56.133     20.650     2.7183     0.0066      15.652      96.614\n",
      "Month_10          56.769     20.571     2.7596     0.0058      16.443      97.096\n",
      "Month_11          20.861     9.0627     2.3018     0.0214      3.0948      38.627\n",
      "Month_12         -2.5484     5.4811    -0.4649     0.6420     -13.293      8.1963\n",
      "Day_2             6.9010     3.6228     1.9049     0.0568     -0.2009      14.003\n",
      "Day_3            -5.3686     3.1391    -1.7102     0.0873     -11.522      0.7851\n",
      "Day_4            -19.264     7.9411    -2.4258     0.0153     -34.831     -3.6967\n",
      "Day_5             36.803     12.509     2.9422     0.0033      12.282      61.324\n",
      "Day_6             1.0551     3.0317     0.3480     0.7278     -4.8880      6.9983\n",
      "Day_7             15.224     5.8557     2.5998     0.0093      3.7447      26.703\n",
      "Day_8            -8.5311     3.4958    -2.4404     0.0147     -15.384     -1.6782\n",
      "Day_9             3.2270     4.2099     0.7665     0.4434     -5.0259      11.480\n",
      "Day_10            1.8046     3.6349     0.4965     0.6196     -5.3211      8.9302\n",
      "Day_11            13.643     4.3815     3.1138     0.0019      5.0539      22.232\n",
      "Day_12            13.460     5.2337     2.5718     0.0101      3.2001      23.720\n",
      "Day_13            4.7203     5.5526     0.8501     0.3953     -6.1646      15.605\n",
      "Day_14            9.5485     4.4566     2.1426     0.0322      0.8122      18.285\n",
      "Day_15            26.497     8.2503     3.2117     0.0013      10.324      42.670\n",
      "Day_16            25.163     8.5821     2.9320     0.0034      8.3393      41.987\n",
      "Day_17            3.0556     5.5728     0.5483     0.5835     -7.8689      13.980\n",
      "Day_18           -5.4389     3.0672    -1.7732     0.0762     -11.452      0.5739\n",
      "Day_19            28.826     9.4053     3.0649     0.0022      10.389      47.264\n",
      "Day_20           -8.3776     2.1042    -3.9813     0.0001     -12.503     -4.2526\n",
      "Day_21           -6.9039     4.6328    -1.4902     0.1362     -15.986      2.1780\n",
      "Day_22            12.740     5.9531     2.1400     0.0324      1.0698      24.410\n",
      "Day_23           -17.584     6.2560    -2.8107     0.0050     -29.848     -5.3198\n",
      "Day_24           -16.470     6.6188    -2.4883     0.0129     -29.445     -3.4945\n",
      "Day_25           -8.5199     3.2795    -2.5979     0.0094     -14.949     -2.0910\n",
      "Day_26            26.683     7.9795     3.3440     0.0008      11.041      42.326\n",
      "Day_27            15.055     4.2743     3.5222     0.0004      6.6761      23.434\n",
      "Day_28            0.5368     3.6171     0.1484     0.8820     -6.5539      7.6275\n",
      "Day_29            9.3536     4.0081     2.3337     0.0196      1.4964      17.211\n",
      "Day_30           -1.3709     3.8940    -0.3521     0.7248     -9.0045      6.2627\n",
      "Day_31            2.6117     8.7787     0.2975     0.7661     -14.597      19.821\n",
      "=================================================================================\n",
      "\n",
      "F-test for Poolability: 222.60\n",
      "P-value: 0.0000\n",
      "Distribution: F(5,6474)\n",
      "\n",
      "Included effects: Entity\n"
     ]
    }
   ],
   "source": [
    "ets_train_data_master = ets_train_data_master.set_index(['Borough', 'Y-M-d'])\n",
    "cols = list(ets_train_data_master.columns)\n",
    "\n",
    "cols.remove('Count')\n",
    "cols.remove('Count_trend')\n",
    "cols.remove('Count_seasonal')\n",
    "cols.remove('Count_error')\n",
    "\n",
    "mod = PanelOLS(ets_train_data_master['Count'], ets_train_data_master[cols],\n",
    "            entity_effects=True, drop_absorbed=True)\n",
    "res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db20bd2fa7790b501c761c1074c8c3d8dd665113807c5097ca05193393e086b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
